{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4870212e-8584-458a-8b68-6b7567dffd9d",
   "metadata": {},
   "source": [
    "# Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_addons numpy pandas tensorflow sklearn nltk spacy textblob gensim scipy seaborn matplotlib minio mlflow wordcloud boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8d1d55-f228-462c-ac0f-dafc2e03bfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/app-root/src/anz_ml_project/notebooks/text_classification_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da87e50-a13b-4621-be58-be2ba8e74011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc4b5c7-a1fc-42e8-8c00-f2987f6803c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path is a list of absolute path strings\n",
    "sys.path.append('/opt/app-root/src/anz_ml_project/')\n",
    "from src.loadingdata.read_dataset import ReadData\n",
    "from src.features.build_features import BuildFeatures\n",
    "from src.modules.build_model import BuildModel\n",
    "from src.modules.train_model import MLflow, TrainModel\n",
    "from src.modules.predict_model import Predictor,Transformer,DownloadArtifact\n",
    "\n",
    "# from src.modules.predict_model import BuildModel\n",
    "# from src.modules.train_model import BuildModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea4e1d0-9de3-4fce-b43d-3a2463510d19",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9230902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# # sys.path is a list of absolute path strings\n",
    "# sys.path.append('/opt/app-root/src/anz_ml_project/')\n",
    "\n",
    "# from src.features.build_features import BuildFeatures\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sklearn.feature_extraction.text as text\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer,SnowballStemmer\n",
    "from textblob import Word\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "# from wordcloud import WordCloudfrom wordcloud import WordCloud\n",
    "from io import StringIO\n",
    "import string\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import itertools\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "\n",
    "import mlflow\n",
    "import warnings\n",
    "\n",
    "from minio import Minio\n",
    "import subprocess\n",
    "import ipynbname\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "\n",
    "tokenizer = ToktokTokenizer()\n",
    "# stopword_list = nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c753d-e8f9-44b0-a54c-d08dae3f5250",
   "metadata": {},
   "source": [
    "# Define a class to read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f450abea-588b-437d-95b0-4506ea7e21cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9501e33e-a845-4ca3-881b-1626b363aee4",
   "metadata": {},
   "source": [
    "# Define a class to preprocess the data and make them ready for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa6d2f-fb71-4758-8d83-30d77ee9ec73",
   "metadata": {},
   "source": [
    "# Define a class for building the Deep learning based model for  NLP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc612a-ca1b-4f80-9a6b-bf3ac92d35df",
   "metadata": {},
   "source": [
    "# Define a class to configur MLFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb9be3b-31d5-4077-8c05-e2dae1da877f",
   "metadata": {},
   "source": [
    "# Define a class for training the model and tracking it with MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ee528-9ae0-42d8-96fa-ee65b6b8b6e1",
   "metadata": {},
   "source": [
    "# Define classes for Deploy simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7f669-cf8c-464c-a4b7-814cac6b408b",
   "metadata": {},
   "source": [
    "# download  artifacts for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070e4ed1-1cad-4341-81d7-fa8780fc89b6",
   "metadata": {},
   "source": [
    "# Initialize the config file for mlflow and Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e397a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HOST = \"http://mlflow:5500\"\n",
    "\n",
    "PROJECT_NAME = \"NlpTc\"\n",
    "EXPERIMENT_NAME = \"NlpLstm\"\n",
    "\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL']='http://minio-ml-workshop:9000'\n",
    "os.environ['AWS_ACCESS_KEY_ID']='minio'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']='minio123'\n",
    "os.environ['AWS_REGION']='us-east-1'\n",
    "os.environ['AWS_BUCKET_NAME']='raw-data-saeed'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f2529-55bb-4a9d-acef-3358eb9b6c1a",
   "metadata": {},
   "source": [
    "\n",
    "## Define a Function to read from Minio S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2201c73-0605-41b1-8f4b-924aae88fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3_server():\n",
    "    minioClient = Minio('minio-ml-workshop:9000',\n",
    "                    access_key='minio',\n",
    "                    secret_key='minio123',\n",
    "                    secure=False)\n",
    "\n",
    "    return minioClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb3ae1c9-5dcb-4bca-bbe2-7d7e026b4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_s3_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22deba8c-4667-4958-b114-93d5c3094fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af49b7ed-6635-42d8-8981-05ec30a53d0a",
   "metadata": {},
   "source": [
    "## SetUp MLFlow to track the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac4f368-4c1d-4743-9dc2-6ca200f8bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow = MLflow(mlflow, HOST,EXPERIMENT_NAME).SetUp_Mlflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2523b21-5c01-448b-b06c-ea39181c408e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1aabb275",
   "metadata": {},
   "source": [
    "# Readinng the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c8f24db-e2bb-4dff-ba49-aa89fda5098c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bank account or service' 'Consumer Loan' 'Credit card'\n",
      " 'Credit reporting' 'Debt collection' 'Money transfers' 'Mortgage'\n",
      " 'Other financial service' 'Payday loan' 'Prepaid card' 'Student loan']\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), array([1383,  894, 1898, 3002, 4138,  155, 3631,   34,  180,  185,  500]))\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), array([ 346,  224,  474,  750, 1034,   39,  908,    9,   45,   46,  125]))\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_labels, test_labels,enc = ReadData(client,S3BucketName = \"raw-data-saeed\",FILE_NAME=\"large_cc_data.csv\").ReadDataFrameData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "409a6120-e387-4d17-aa38-7768f7c279b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from src.features.build_features import BuildFeatures\n",
    "train_data.shape\n",
    "\n",
    "test_labels.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f116d8-378f-42ba-ae65-f6bda55a4e63",
   "metadata": {},
   "source": [
    "# Prepare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e347a28f-63d6-4aa1-aa8e-7f24b2ce0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "BFCLASS = BuildFeatures(TRAIN_DATA=train_data,TEST_DATA=test_data,TRAIN_LABELS=train_labels,TEST_LABELS=test_labels, CLIENT= client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c1e5e30-daed-4acd-8da9-028c765b79ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Sequence length is 388 .\n",
      "Found 19236 unique tokens.\n",
      "Shape of train data tensor: (16000, 388)\n",
      "Shape of train label tensor: (16000, 11)\n",
      "Shape of test label tensor: (4000, 11)\n"
     ]
    }
   ],
   "source": [
    "train_data,test_data,train_labels , test_labels,word_index,tokenizer,MAX_SEQUENCE_LENGTH = BFCLASS.PreProcessingTextData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f577c518",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Deep Learning define, train and test model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752ffe69-6213-4614-aa12-32b1cbdfd885",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b740adae-5c4f-4d0c-90ef-b8cfb9da8720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 388, 50)           961850    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 388, 200)          120800    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               935936    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 11)                5643      \n",
      "=================================================================\n",
      "Total params: 2,024,229\n",
      "Trainable params: 2,024,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = BuildModel(WORD_INDEX=word_index, MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH, EMWEIGHTS=[]).SetupModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c37d919-de54-4565-a4b6-74a58e4f1329",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9aca2b-be70-4ca2-b89d-c33df03f2d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "250/250 [==============================] - 342s 1s/step - loss: 1.1854 - acc: 0.6097 - val_loss: 0.8326 - val_acc: 0.7370\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.7505 - acc: 0.7686 - val_loss: 0.7733 - val_acc: 0.7715\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.6288 - acc: 0.8080 - val_loss: 0.6781 - val_acc: 0.7893\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.5392 - acc: 0.8356 - val_loss: 0.6653 - val_acc: 0.7995\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.4822 - acc: 0.8521 - val_loss: 0.6285 - val_acc: 0.8127\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.4327 - acc: 0.8685 - val_loss: 0.6200 - val_acc: 0.8155\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.3936 - acc: 0.8817 - val_loss: 0.6269 - val_acc: 0.8145\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.3634 - acc: 0.8910 - val_loss: 0.6050 - val_acc: 0.8175\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.3315 - acc: 0.9001 - val_loss: 0.6353 - val_acc: 0.8230\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.3038 - acc: 0.9094 - val_loss: 0.6380 - val_acc: 0.8205\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.2840 - acc: 0.9156 - val_loss: 0.6633 - val_acc: 0.8177\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.2616 - acc: 0.9200 - val_loss: 0.6935 - val_acc: 0.8127\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.2435 - acc: 0.9251 - val_loss: 0.6797 - val_acc: 0.8173\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 335s 1s/step - loss: 0.2278 - acc: 0.9296 - val_loss: 0.7436 - val_acc: 0.8098\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 334s 1s/step - loss: 0.2102 - acc: 0.9337 - val_loss: 0.7183 - val_acc: 0.8100\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - 333s 1s/step - loss: 0.1987 - acc: 0.9378 - val_loss: 0.7512 - val_acc: 0.8140\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - 333s 1s/step - loss: 0.1829 - acc: 0.9444 - val_loss: 0.7820 - val_acc: 0.8115\n",
      "Epoch 18/30\n",
      "133/250 [==============>...............] - ETA: 2:21 - loss: 0.0759 - acc: 0.9750"
     ]
    }
   ],
   "source": [
    "model, history= TrainModel(model, mlflow, tokenizer, enc,train_data, train_labels,test_data, test_labels,HOST, EXPERIMENT_NAME, BATCH_SIZE=64,EPOCHS=30).ModelTraining()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0644c-f188-43c9-a17c-c327145a641e",
   "metadata": {},
   "source": [
    "### Plot the training and testing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9428b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves :RNN - LSTM',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7712ce-2e36-476e-80fa-68b568cb52f5",
   "metadata": {},
   "source": [
    "#### Plot the training and testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d876903",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
    "plt.legend(['Training acc', 'Validation acc'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves :RNN - LSTM',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e411f40-3785-486c-8db3-0db25e85f9a9",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61836da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions on test data\n",
    "predicted=model.predict(test_data)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89568132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model evaluation\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "precision, recall, fscore, support = score(test_labels, predicted.round())\n",
    "print('precision: \\n{}'.format(precision))\n",
    "print('recall: \\n{}'.format(recall))\n",
    "print('fscore: \\n{}'.format(fscore))\n",
    "print('support: \\n{}'.format(support))\n",
    "print(\"############################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a35fdb6-cc8c-42ca-a15d-6815de5f7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat = confusion_matrix(test_labels.argmax(axis=1), predicted.argmax(axis=1))\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"BuPu\",xticklabels=enc.classes_,yticklabels=enc.classes_)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c9850-8bfe-42c5-839f-2509197ca1b3",
   "metadata": {},
   "source": [
    "### Download the artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d516f5b-c95f-46f5-93c4-21f7b01e2d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DownloadArtifact(mlflow, MODEL_NAME='lstmt1', MODEL_VRSION='1').download_artifacts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0facfe75-65cd-47fd-b06a-dbc61865aa4c",
   "metadata": {},
   "source": [
    "###  Test with Actual  data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188c78cd-dcdd-4e80-b781-45f7942617c8",
   "metadata": {},
   "source": [
    "#### Define a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99c611-218f-4c0f-b9d5-7ad65a4f9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = {\"data\":\n",
    "  {\n",
    "\n",
    "\n",
    "        \"names\":\n",
    "            [\n",
    "              \"Debt collection\"\n",
    "            ],\n",
    "      \"ndarray\": [\"could longer pay enormous charge hired company nl take either nothing pay day loan company accept term get several letter week threatened take civil action get check\"]\n",
    "\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04193d4a-0420-4779-8fdd-1e5b057140d7",
   "metadata": {},
   "source": [
    "#### Transform the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b28e8-ab1c-4720-b50e-6d43517b9a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ready_data = Transformer().transform_input(sample_data,\"name\",\"meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8f20a-a765-4a04-8003-967d83581a9d",
   "metadata": {},
   "source": [
    "### Test the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d99aca-5668-4793-a4c7-fe59cac7768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Predictor().predict(ready_data,\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c426e-40b7-4b79-90f3-fa8fab06010d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994de0ac-7ef5-40c6-96c0-d2711897767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Predictor().predict(ready_data,ready_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8dba8-b327-469a-a2b9-95b52e40dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(ready_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c922df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c09ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0558f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, predicted.round(),target_names=enc.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92b61f",
   "metadata": {},
   "source": [
    "After hours of training we get good results with LSTM(type of recurrent neural network) compared to CNN. From the learning curves it is clear the model needs to be tuned for overfitting by selecting hyperparameters such as no of epochs via early stopping and dropout for regularization.\n",
    "\n",
    "We could further improve our final result by ensembling our xgboost and Neural network models by using Logistic Regression as our base model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a43af4-e74f-43f9-a69d-c04475179984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10d220c55dad87bc296f91a276cffc08c658df4f112171a2982baf6251a25e4e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
